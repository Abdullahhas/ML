{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "233129dc-a548-4e35-885d-370a4e28a6c0",
   "metadata": {},
   "source": [
    "# Titanic Passenger Survival Prediction System"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b60967-4f3a-42cd-9f8a-2463a0876a70",
   "metadata": {},
   "source": [
    "## SU Meta Description\n",
    "<p>\n",
    "Discover the Titanic Passenger Survival Prediction System, a machine learning model that analyzes passenger data to predict survival chances with accuracy and insights.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a570ff65-9237-440f-b13c-a77c2cf878a3",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec3ad8a-e98c-4bf9-b52d-f49dfcabbe22",
   "metadata": {},
   "source": [
    "##### **Definition** A binary classification ML task that predicts whether a passenger survived (1) or did not survive (0) the Titanic disaster using their attributes (e.g., class, sex, age, fare, etc.)\n",
    "##### **Application** It is mainly used for learning data science, testing ML algorithms, and gaining insights into survival factors like gender and class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd0ff15-ba72-4239-ab4b-c4d92735b874",
   "metadata": {},
   "source": [
    "##  Input and Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5139ba-684d-4a78-88a5-5e03039c1cdc",
   "metadata": {},
   "source": [
    "###  Inputs (Features / Attributes)\n",
    "\n",
    "| **Input Feature/Attribute**  |      **Possible Values**          |\n",
    "| ------------ | ---------------------------------- |\n",
    "| **PClass**   | First, Second, Third               |\n",
    "| **Gender**   | Male, Female                       |\n",
    "| **Sibling**  | Zero, One, Two, Three                     |\n",
    "| **Embarked** | Southampton, Cherbourg, Queenstown |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e386e522-f98d-4ef1-8c91-4ba0112afb79",
   "metadata": {},
   "source": [
    "### Output (Prediction)\n",
    "\n",
    "| **Output Attribute** | **Possbile Values** |\n",
    "| -------------------- | ------------------------- |\n",
    "| **Survived**         | Yes, No                   |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673306c0-cb95-48cb-99d6-8c0c64f99068",
   "metadata": {},
   "source": [
    "### Examples (Titanic Dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52252620-b33c-4083-bee2-466cb3259518",
   "metadata": {},
   "source": [
    "| PClass | Gender | Sibling | Embarked    | Survived |\n",
    "| :----: | :----: | :-----: | :---------- | :------: |\n",
    "|  Third |  Male  |   One   | Southampton |    No    |\n",
    "| Second | Female |   Zero  | Southampton |    Yes   |\n",
    "|  Third |  Male  |   Zero  | Southampton |    No    |\n",
    "|  Third | Female |  Three  | Southampton |    Yes   |\n",
    "|  Third |  Male  |   Zero  | Queenstown  |    No    |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cbda59-3faf-4218-8f10-017a06dd733f",
   "metadata": {},
   "source": [
    "## Developer & System Information\n",
    "\n",
    "|                                |                                                                                         |\n",
    "| ------------------------------------------- | --------------------------------------------------------------------------------------------------- |\n",
    "| **Developer Name**                          | Mr. Mohsin Afzal, Dr. Rao Muhammad Adeel Nawab                                                      |\n",
    "| **LinkedIn** (Mohsin Afzal)                 | [Mohsin Afzal](https://www.linkedin.com/in/mohsin-mahmood-7a2139347/)                               |\n",
    "| **LinkedIn** (Dr. Rao Muhammad Adeel Nawab) | [Dr. Rao Muhammad Adeel Nawab](https://www.linkedin.com/in/rao-muhammad-adeel-nawab/)               |\n",
    "| **Program Name**                            | titanic\\_project                                                                                    |\n",
    "| **IDE**                                     | Jupyter Notebook                                                                                    |\n",
    "| **Programming Language**                    | Python 3.13.5                                                                                       |\n",
    "| **Operating System**                        | Windows 11                                                                                          |\n",
    "| **Libraries**                               | NumPy 2.1.3, Pandas 2.2.3, Pickle (built-in), scikit-learn 1.6.1, PrettyTable 3.16.0, Astropy 7.0.0 |\n",
    "| **Date of Completion**                      | 9-Sep-2025                                                                                          |\n",
    "| **Website**                                 | [ilmoirfan.ai](https://ilmoirfan.ai), [ilmoirfan.com](https://ilmoirfan.com)                        |\n",
    "| **Email**                                   | [info@ilmoirfan.ai](mailto:info@ilmoirfan.ai), [info@ilmoirfan.com](mailto:info@ilmoirfan.com)      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c917f86e-f0d3-4d1a-9909-adaed55388fa",
   "metadata": {},
   "source": [
    "##  Table of Content\n",
    "- Step 1: Import Libraries  \n",
    "\n",
    "- Step 2: Load Sample Data  \n",
    "\n",
    "- Step 3: Understand and Pre-process Sample Data  \n",
    "  - Step 3.1: Understand Sample Data  \n",
    "  - Step 3.2: Pre-process Sample Data  \n",
    "\n",
    "- Step 4: Feature Extraction  \n",
    "\n",
    "- Step 5: Label Encoding the Sample Data (Input and Output is converted in Numeric Representation)  \n",
    "  - Step 5.1: Train the Label Encoder  \n",
    "  - Step 5.2: Label Encode the Output  \n",
    "  - Step 5.3: Label Encode the Input  \n",
    "\n",
    "- Step 6: Execute the Training Phase  \n",
    "  - Step 6.1: Splitting Sample Data into Training Data and Testing Data  \n",
    "  - Step 6.2: Splitting Input Vectors and Outputs / Labels of Training Data  \n",
    "  - Step 6.3: Train the Support Vector Classifier  \n",
    "  - Step 6.4: Save the Trained Model  \n",
    "\n",
    "- Step 7: Execute the Testing Phase  \n",
    "  - Step 7.1: Splitting Input Vectors and Outputs/Labels of Testing Data  \n",
    "  - Step 7.2: Load the Saved Model  \n",
    "  - Step 7.3: Evaluate the Machine Learning Model  \n",
    "    - Step 7.3.1: Make Predictions with the Trained Models on Testing Data  \n",
    "  - Step 7.4: Calculate the Accuracy Score  \n",
    "\n",
    "- Step 8: Execute the Application Phase  \n",
    "  - Step 8.1: Take Input from User  \n",
    "  - Step 8.2: Convert User Input into Feature Vector (Exactly Same as Feature Vectors of Sample Data)  \n",
    "  - Step 8.3: Label Encoding of Feature Vector (Exactly Same as Label Encoded Feature Vectors of Sample Data)  \n",
    "  - Step 8.4: Load the Saved Model  \n",
    "  - Step 8.5: Model Prediction  \n",
    "    - Step 8.5.1: Apply Model on the Label Encoded Feature Vector of unseen instance and return Prediction to the User  \n",
    "\n",
    "- Step 9: Execute the Feedback Phase  \n",
    "  - Step 9.1: Collect Feedback from Users and Domain Experts on Performance of the Model Deployed in the Real World  \n",
    "  - Step 9.2: Make a List of Potential Improvements  \n",
    "  - Step 9.3: Improve the Model Based on Feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cde222f-155c-4d30-8006-fb4fa7946120",
   "metadata": {},
   "source": [
    "## Code – Titanic Prediction Survival"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a5bee8-116f-404a-aa02-689b591f747f",
   "metadata": {},
   "source": [
    "###  Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c21308b8-c0de-4b9c-9262-3577bc503a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Purpose of this code:\n",
    "----------------------\n",
    "This script imports the required libraries for building and evaluating a \n",
    "machine learning model. It sets up tools for data manipulation, preprocessing, \n",
    "splitting datasets, training a Support Vector Machine (SVM) model, \n",
    "evaluating accuracy, and displaying results in tabular form.\n",
    "\"\"\"\n",
    "\n",
    "# Import numerical computing library (used for arrays, math operations, etc.)\n",
    "import numpy as np\n",
    "\n",
    "# Import data manipulation library (used for DataFrames, reading/writing data, etc.)\n",
    "import pandas as pd\n",
    "\n",
    "# Import pickle (used for saving and loading Python objects/models)\n",
    "import pickle\n",
    "\n",
    "# Import train_test_split (used to divide dataset into training and testing sets)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import LabelEncoder (used to convert categorical values into numeric codes)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Import Support Vector Machine (SVM) model from scikit-learn\n",
    "from sklearn import svm\n",
    "\n",
    "# Import accuracy_score (used to evaluate the performance of the model)\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Import PrettyTable (used to display results in a clean, table format)\n",
    "from prettytable import PrettyTable   \n",
    "\n",
    "# Import Table and Column from astropy (used to create structured tables)\n",
    "from astropy.table import Table, Column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9345e11a-0809-48f1-9845-8fbf63151f7b",
   "metadata": {},
   "source": [
    "### Step 2: Load Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "947b5a7b-6bc9-47e4-9a61-210c3d2700a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Sample Data:\n",
      "============\n",
      "\n",
      "    PClass  Gender Sibling     Embarked Survived\n",
      "0    Third    Male     One  Southampton       No\n",
      "1   Second  Female    Zero  Southampton      Yes\n",
      "2    Third    Male    Zero  Southampton       No\n",
      "3    Third  Female   Three  Southampton      Yes\n",
      "4    Third    Male    Zero   Queenstown       No\n",
      "5    First  Female   Three  Southampton      Yes\n",
      "6    Third    Male    Zero  Southampton       No\n",
      "7    Third    Male    Zero  Southampton      Yes\n",
      "8    First    Male    Zero  Southampton       No\n",
      "9   Second    Male    Zero  Southampton      Yes\n",
      "10   Third    Male     One   Queenstown       No\n",
      "11   First    Male    Zero    Cherbourg      Yes\n",
      "12   First    Male    Zero    Cherbourg       No\n",
      "13  Second  Female    Zero  Southampton      Yes\n",
      "14  Second    Male    Zero  Southampton       No\n",
      "15   Third    Male     One    Cherbourg      Yes\n",
      "16   Third    Male     Two    Cherbourg       No\n",
      "17   Third    Male    Zero  Southampton      Yes\n",
      "18   Third    Male    Zero  Southampton       No\n",
      "19   Third  Female     One    Cherbourg      Yes\n",
      "20   Third    Male    Zero    Cherbourg       No\n",
      "21   First  Female    Zero  Southampton      Yes\n",
      "22   First    Male    Zero    Cherbourg       No\n",
      "23  Second  Female    Zero  Southampton      Yes\n",
      "24   Third  Female     One  Southampton       No\n",
      "25   Third  Female    Zero  Southampton      Yes\n",
      "26   Third    Male    Zero  Southampton       No\n",
      "27   Third    Male    Zero  Southampton      Yes\n",
      "28   Third    Male    Zero  Southampton       No\n",
      "29   Third  Female     One   Queenstown      Yes\n",
      "30   Third  Female     Two  Southampton       No\n",
      "31   First  Female    Zero    Cherbourg      Yes\n",
      "32   Third    Male     Two  Southampton       No\n",
      "33   First  Female    Zero  Southampton      Yes\n",
      "34   First    Male     One    Cherbourg       No\n",
      "35   First  Female    Zero  Southampton      Yes\n",
      "36   First    Male     One  Southampton       No\n",
      "37   Third  Female     One   Queenstown      Yes\n",
      "38   Third  Female     One  Southampton       No\n",
      "39  Second  Female     One  Southampton      Yes\n",
      "40  Second  Female     One  Southampton       No\n",
      "41   Third  Female    Zero   Queenstown      Yes\n",
      "42   Third    Male    Zero    Cherbourg       No\n",
      "43   First  Female    Zero    Cherbourg      Yes\n",
      "44   Third    Male   Three  Southampton       No\n",
      "45   Third  Female     One  Southampton      Yes\n",
      "46   Third    Male    Zero  Southampton       No\n",
      "47   Third    Male    Zero  Southampton      Yes\n",
      "48   Third    Male     One  Southampton       No\n",
      "49  Second  Female    Zero  Southampton      Yes\n",
      "50   First    Male   Three  Southampton       No\n",
      "51   Third    Male    Zero  Southampton      Yes\n",
      "52   Third  Female     One  Southampton       No\n",
      "53  Second  Female    Zero  Southampton      Yes\n",
      "54   Third  Female   Three  Southampton       No\n",
      "55   Third  Female    Zero  Southampton      Yes\n",
      "56   Third  Female    Zero  Southampton       No\n",
      "57   Third  Female     One  Southampton      Yes\n",
      "58   Third    Male    Zero    Cherbourg       No\n",
      "59   Third    Male    Zero  Southampton      Yes\n",
      "60  Second    Male    Zero  Southampton       No\n",
      "61   First  Female     One  Southampton      Yes\n",
      "62   Third    Male   Three   Queenstown       No\n",
      "63   Third  Female    Zero   Queenstown      Yes\n",
      "64  Second  Female    Zero  Southampton       No\n",
      "65   Third  Female    Zero    Cherbourg      Yes\n",
      "66   Third    Male    Zero  Southampton       No\n",
      "67  Second    Male    Zero  Southampton      Yes\n",
      "68   Third    Male    Zero  Southampton       No\n",
      "69   First    Male    Zero  Southampton      Yes\n",
      "70   Third    Male    Zero  Southampton       No\n",
      "71  Second    Male     Two  Southampton      Yes\n",
      "72   Third    Male    Zero    Cherbourg       No\n",
      "73   Third  Female    Zero  Southampton      Yes\n",
      "74   Third  Female    Zero  Southampton       No\n",
      "75   First  Female     One  Southampton      Yes\n",
      "76   Third    Male     One  Southampton       No\n",
      "77  Second  Female    Zero  Southampton      Yes\n",
      "78   Third    Male    Zero  Southampton       No\n",
      "79   Third  Female     Two  Southampton      Yes\n",
      "80   Third    Male     Two  Southampton       No\n",
      "81   Third  Female    Zero  Southampton      Yes\n",
      "82   Third    Male    Zero  Southampton       No\n",
      "83   First    Male     One  Southampton      Yes\n",
      "84  Second    Male    Zero  Southampton       No\n",
      "85   Third  Female     One   Queenstown      Yes\n",
      "86  Second    Male    Zero  Southampton       No\n",
      "87   First  Female     One  Southampton      Yes\n",
      "88   Third    Male    Zero  Southampton       No\n",
      "89  Second  Female    Zero  Southampton      Yes\n",
      "90  Second    Male    Zero  Southampton       No\n",
      "91  Second  Female    Zero  Southampton      Yes\n",
      "92   Third    Male    Zero    Cherbourg       No\n",
      "93   First    Male     One  Southampton      Yes\n",
      "94   First    Male     One  Southampton       No\n",
      "95   Third    Male     One    Cherbourg      Yes\n",
      "96   Third    Male     One   Queenstown       No\n",
      "97   Third    Male     One  Southampton      Yes\n",
      "98  Second    Male     One  Southampton       No\n",
      "99   Third    Male     One  Southampton      Yes\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Purpose of this section:\n",
    "-------------------------\n",
    "This part of the code loads a sample dataset from a CSV file into a \n",
    "pandas DataFrame. It then displays the dataset so that students can \n",
    "see the raw data being used for further processing and model training.\n",
    "\"\"\"\n",
    "\n",
    "# Read the CSV file and load it into a pandas DataFrame\n",
    "# 'sample-data.csv' should be present in the working directory\n",
    "sample_data = pd.read_csv(\"sample-data.csv\")\n",
    "\n",
    "# Print a header to indicate that sample data is being displayed\n",
    "print(\"\\n\\nSample Data:\")\n",
    "print(\"============\\n\")\n",
    "\n",
    "# Configure pandas to display all rows and columns (so nothing gets hidden with '...')\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "\n",
    "# Print the complete dataset\n",
    "print(sample_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a946f6b0-37d1-48be-a4d8-ebb454ab04ba",
   "metadata": {},
   "source": [
    "### Step 3: Understand and Pre-process Sample Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11cd694-6a79-4fa8-a171-70318fadee52",
   "metadata": {},
   "source": [
    "####  Step 3.1: Understand Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5e4f6f32-40d1-4dbd-84c8-b53fc95cd142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Attributes in Sample Data:\n",
      "==========================\n",
      "\n",
      "Index(['PClass', 'Gender', 'Sibling', 'Embarked', 'Survived'], dtype='object')\n",
      "\n",
      "\n",
      "Number of Instances in Sample Data: 100\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Purpose of this section:\n",
    "-------------------------\n",
    "This part of the code helps us understand the dataset by:\n",
    "1. Printing the names of all attributes (columns) in the DataFrame.\n",
    "2. Showing the total number of instances (rows) available in the dataset.\n",
    "\"\"\"\n",
    "\n",
    "# Print a header for clarity\n",
    "print(\"\\n\\nAttributes in Sample Data:\")\n",
    "print(\"==========================\\n\")\n",
    "\n",
    "# Display all column names (attributes) in the dataset\n",
    "print(sample_data.columns)\n",
    "\n",
    "# Print a header for instance count\n",
    "print(\"\\n\\nNumber of Instances in Sample Data:\", sample_data[\"PClass\"].count())\n",
    "print(\"========================================\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9e3353-a52e-4bff-9d81-383d5937f114",
   "metadata": {},
   "source": [
    "#### Step 3.2: Pre-process Sample Data\n",
    "o   Sample Data is already Preprocessed\n",
    "o   No Preprocessing needs to be Performed "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834f915f-6fdf-47e0-958a-b70523ccb676",
   "metadata": {},
   "source": [
    "#### Step 4: Feature Extraction\n",
    "o   Features are already Extracted\n",
    "o   No Feature Extraction needs to be Performed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c66837-e482-453c-a66a-d6af7b035a9d",
   "metadata": {},
   "source": [
    "### Step 5: Label Encoding the Sample Data (Input and Output is converted in Numeric Representation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4bd6ca-bf3d-424d-92cc-bf591adaf8dd",
   "metadata": {},
   "source": [
    "#### Step 5.1: Train the Label Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cab4ed3b-9390-44dc-a795-304174f784ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LabelEncoder</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.LabelEncoder.html\">?<span>Documentation for LabelEncoder</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LabelEncoder()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Purpose of this section:\n",
    "-------------------------\n",
    "This part of the code sets up and trains Label Encoders. \n",
    "Label Encoding is used to convert categorical values (like 'Male', 'Female', 'First', 'Second') \n",
    "into numeric codes that machine learning algorithms can work with.\n",
    "\n",
    "Steps:\n",
    "1. Define sample label categories for each attribute.\n",
    "2. Initialize a LabelEncoder for each attribute.\n",
    "3. Train (fit) each LabelEncoder with its respective category values.\n",
    "\"\"\"\n",
    "\n",
    "# Define label categories for each feature\n",
    "# These are possible values each column can have in the dataset\n",
    "pclass = pd.DataFrame({\"Pclass\": [\"First\", \"Second\", \"Third\"]})\n",
    "gender = pd.DataFrame({\"Gender\": [\"Male\", \"Female\"]})\n",
    "sibling = pd.DataFrame({\"Sibling\": [\"Zero\", \"One\", \"Two\", \"Three\"]})\n",
    "embarked = pd.DataFrame({\"Embarked\": [\"Southampton\", \"Cherbourg\", \"Queenstown\"]})\n",
    "survived = pd.DataFrame({\"Survived\": [\"Yes\", \"No\"]})\n",
    "\n",
    "# Create LabelEncoder objects for each categorical column\n",
    "pclass_label_encoder = LabelEncoder()\n",
    "gender_label_encoder = LabelEncoder()\n",
    "sibling_label_encoder = LabelEncoder()\n",
    "embarked_label_encoder = LabelEncoder()\n",
    "survived_label_encoder = LabelEncoder()\n",
    "\n",
    "# Train (fit) the encoders on the given categories\n",
    "# np.ravel() flattens the DataFrame column into a 1D array for the encoder\n",
    "pclass_label_encoder.fit(np.ravel(pclass))\n",
    "gender_label_encoder.fit(np.ravel(gender))\n",
    "sibling_label_encoder.fit(np.ravel(sibling))\n",
    "embarked_label_encoder.fit(np.ravel(embarked))\n",
    "survived_label_encoder.fit(np.ravel(survived))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c69b79e-7f2b-442e-9391-c9418f4f58b9",
   "metadata": {},
   "source": [
    "#### Step 5.2: Label Encode the Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b3f94c3c-4a4f-4380-ae20-f40c55485537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Survived Attribute After Label Encoding:\n",
      "========================================\n",
      "\n",
      "   Survived  encoded_survived\n",
      "0        No                 0\n",
      "1       Yes                 1\n",
      "2        No                 0\n",
      "3       Yes                 1\n",
      "4        No                 0\n",
      "5       Yes                 1\n",
      "6        No                 0\n",
      "7       Yes                 1\n",
      "8        No                 0\n",
      "9       Yes                 1\n",
      "10       No                 0\n",
      "11      Yes                 1\n",
      "12       No                 0\n",
      "13      Yes                 1\n",
      "14       No                 0\n",
      "15      Yes                 1\n",
      "16       No                 0\n",
      "17      Yes                 1\n",
      "18       No                 0\n",
      "19      Yes                 1\n",
      "20       No                 0\n",
      "21      Yes                 1\n",
      "22       No                 0\n",
      "23      Yes                 1\n",
      "24       No                 0\n",
      "25      Yes                 1\n",
      "26       No                 0\n",
      "27      Yes                 1\n",
      "28       No                 0\n",
      "29      Yes                 1\n",
      "30       No                 0\n",
      "31      Yes                 1\n",
      "32       No                 0\n",
      "33      Yes                 1\n",
      "34       No                 0\n",
      "35      Yes                 1\n",
      "36       No                 0\n",
      "37      Yes                 1\n",
      "38       No                 0\n",
      "39      Yes                 1\n",
      "40       No                 0\n",
      "41      Yes                 1\n",
      "42       No                 0\n",
      "43      Yes                 1\n",
      "44       No                 0\n",
      "45      Yes                 1\n",
      "46       No                 0\n",
      "47      Yes                 1\n",
      "48       No                 0\n",
      "49      Yes                 1\n",
      "50       No                 0\n",
      "51      Yes                 1\n",
      "52       No                 0\n",
      "53      Yes                 1\n",
      "54       No                 0\n",
      "55      Yes                 1\n",
      "56       No                 0\n",
      "57      Yes                 1\n",
      "58       No                 0\n",
      "59      Yes                 1\n",
      "60       No                 0\n",
      "61      Yes                 1\n",
      "62       No                 0\n",
      "63      Yes                 1\n",
      "64       No                 0\n",
      "65      Yes                 1\n",
      "66       No                 0\n",
      "67      Yes                 1\n",
      "68       No                 0\n",
      "69      Yes                 1\n",
      "70       No                 0\n",
      "71      Yes                 1\n",
      "72       No                 0\n",
      "73      Yes                 1\n",
      "74       No                 0\n",
      "75      Yes                 1\n",
      "76       No                 0\n",
      "77      Yes                 1\n",
      "78       No                 0\n",
      "79      Yes                 1\n",
      "80       No                 0\n",
      "81      Yes                 1\n",
      "82       No                 0\n",
      "83      Yes                 1\n",
      "84       No                 0\n",
      "85      Yes                 1\n",
      "86       No                 0\n",
      "87      Yes                 1\n",
      "88       No                 0\n",
      "89      Yes                 1\n",
      "90       No                 0\n",
      "91      Yes                 1\n",
      "92       No                 0\n",
      "93      Yes                 1\n",
      "94       No                 0\n",
      "95      Yes                 1\n",
      "96       No                 0\n",
      "97      Yes                 1\n",
      "98       No                 0\n",
      "99      Yes                 1\n",
      "\n",
      "\n",
      "Original Sample Data:\n",
      "=====================\n",
      "\n",
      "    PClass  Gender Sibling     Embarked Survived\n",
      "0    Third    Male     One  Southampton       No\n",
      "1   Second  Female    Zero  Southampton      Yes\n",
      "2    Third    Male    Zero  Southampton       No\n",
      "3    Third  Female   Three  Southampton      Yes\n",
      "4    Third    Male    Zero   Queenstown       No\n",
      "5    First  Female   Three  Southampton      Yes\n",
      "6    Third    Male    Zero  Southampton       No\n",
      "7    Third    Male    Zero  Southampton      Yes\n",
      "8    First    Male    Zero  Southampton       No\n",
      "9   Second    Male    Zero  Southampton      Yes\n",
      "10   Third    Male     One   Queenstown       No\n",
      "11   First    Male    Zero    Cherbourg      Yes\n",
      "12   First    Male    Zero    Cherbourg       No\n",
      "13  Second  Female    Zero  Southampton      Yes\n",
      "14  Second    Male    Zero  Southampton       No\n",
      "15   Third    Male     One    Cherbourg      Yes\n",
      "16   Third    Male     Two    Cherbourg       No\n",
      "17   Third    Male    Zero  Southampton      Yes\n",
      "18   Third    Male    Zero  Southampton       No\n",
      "19   Third  Female     One    Cherbourg      Yes\n",
      "20   Third    Male    Zero    Cherbourg       No\n",
      "21   First  Female    Zero  Southampton      Yes\n",
      "22   First    Male    Zero    Cherbourg       No\n",
      "23  Second  Female    Zero  Southampton      Yes\n",
      "24   Third  Female     One  Southampton       No\n",
      "25   Third  Female    Zero  Southampton      Yes\n",
      "26   Third    Male    Zero  Southampton       No\n",
      "27   Third    Male    Zero  Southampton      Yes\n",
      "28   Third    Male    Zero  Southampton       No\n",
      "29   Third  Female     One   Queenstown      Yes\n",
      "30   Third  Female     Two  Southampton       No\n",
      "31   First  Female    Zero    Cherbourg      Yes\n",
      "32   Third    Male     Two  Southampton       No\n",
      "33   First  Female    Zero  Southampton      Yes\n",
      "34   First    Male     One    Cherbourg       No\n",
      "35   First  Female    Zero  Southampton      Yes\n",
      "36   First    Male     One  Southampton       No\n",
      "37   Third  Female     One   Queenstown      Yes\n",
      "38   Third  Female     One  Southampton       No\n",
      "39  Second  Female     One  Southampton      Yes\n",
      "40  Second  Female     One  Southampton       No\n",
      "41   Third  Female    Zero   Queenstown      Yes\n",
      "42   Third    Male    Zero    Cherbourg       No\n",
      "43   First  Female    Zero    Cherbourg      Yes\n",
      "44   Third    Male   Three  Southampton       No\n",
      "45   Third  Female     One  Southampton      Yes\n",
      "46   Third    Male    Zero  Southampton       No\n",
      "47   Third    Male    Zero  Southampton      Yes\n",
      "48   Third    Male     One  Southampton       No\n",
      "49  Second  Female    Zero  Southampton      Yes\n",
      "50   First    Male   Three  Southampton       No\n",
      "51   Third    Male    Zero  Southampton      Yes\n",
      "52   Third  Female     One  Southampton       No\n",
      "53  Second  Female    Zero  Southampton      Yes\n",
      "54   Third  Female   Three  Southampton       No\n",
      "55   Third  Female    Zero  Southampton      Yes\n",
      "56   Third  Female    Zero  Southampton       No\n",
      "57   Third  Female     One  Southampton      Yes\n",
      "58   Third    Male    Zero    Cherbourg       No\n",
      "59   Third    Male    Zero  Southampton      Yes\n",
      "60  Second    Male    Zero  Southampton       No\n",
      "61   First  Female     One  Southampton      Yes\n",
      "62   Third    Male   Three   Queenstown       No\n",
      "63   Third  Female    Zero   Queenstown      Yes\n",
      "64  Second  Female    Zero  Southampton       No\n",
      "65   Third  Female    Zero    Cherbourg      Yes\n",
      "66   Third    Male    Zero  Southampton       No\n",
      "67  Second    Male    Zero  Southampton      Yes\n",
      "68   Third    Male    Zero  Southampton       No\n",
      "69   First    Male    Zero  Southampton      Yes\n",
      "70   Third    Male    Zero  Southampton       No\n",
      "71  Second    Male     Two  Southampton      Yes\n",
      "72   Third    Male    Zero    Cherbourg       No\n",
      "73   Third  Female    Zero  Southampton      Yes\n",
      "74   Third  Female    Zero  Southampton       No\n",
      "75   First  Female     One  Southampton      Yes\n",
      "76   Third    Male     One  Southampton       No\n",
      "77  Second  Female    Zero  Southampton      Yes\n",
      "78   Third    Male    Zero  Southampton       No\n",
      "79   Third  Female     Two  Southampton      Yes\n",
      "80   Third    Male     Two  Southampton       No\n",
      "81   Third  Female    Zero  Southampton      Yes\n",
      "82   Third    Male    Zero  Southampton       No\n",
      "83   First    Male     One  Southampton      Yes\n",
      "84  Second    Male    Zero  Southampton       No\n",
      "85   Third  Female     One   Queenstown      Yes\n",
      "86  Second    Male    Zero  Southampton       No\n",
      "87   First  Female     One  Southampton      Yes\n",
      "88   Third    Male    Zero  Southampton       No\n",
      "89  Second  Female    Zero  Southampton      Yes\n",
      "90  Second    Male    Zero  Southampton       No\n",
      "91  Second  Female    Zero  Southampton      Yes\n",
      "92   Third    Male    Zero    Cherbourg       No\n",
      "93   First    Male     One  Southampton      Yes\n",
      "94   First    Male     One  Southampton       No\n",
      "95   Third    Male     One    Cherbourg      Yes\n",
      "96   Third    Male     One   Queenstown       No\n",
      "97   Third    Male     One  Southampton      Yes\n",
      "98  Second    Male     One  Southampton       No\n",
      "99   Third    Male     One  Southampton      Yes\n",
      "\n",
      "\n",
      "Sample Data after Label Encoding of Output:\n",
      "===========================================\n",
      "\n",
      "    PClass  Gender Sibling     Embarked  Survived\n",
      "0    Third    Male     One  Southampton         0\n",
      "1   Second  Female    Zero  Southampton         1\n",
      "2    Third    Male    Zero  Southampton         0\n",
      "3    Third  Female   Three  Southampton         1\n",
      "4    Third    Male    Zero   Queenstown         0\n",
      "5    First  Female   Three  Southampton         1\n",
      "6    Third    Male    Zero  Southampton         0\n",
      "7    Third    Male    Zero  Southampton         1\n",
      "8    First    Male    Zero  Southampton         0\n",
      "9   Second    Male    Zero  Southampton         1\n",
      "10   Third    Male     One   Queenstown         0\n",
      "11   First    Male    Zero    Cherbourg         1\n",
      "12   First    Male    Zero    Cherbourg         0\n",
      "13  Second  Female    Zero  Southampton         1\n",
      "14  Second    Male    Zero  Southampton         0\n",
      "15   Third    Male     One    Cherbourg         1\n",
      "16   Third    Male     Two    Cherbourg         0\n",
      "17   Third    Male    Zero  Southampton         1\n",
      "18   Third    Male    Zero  Southampton         0\n",
      "19   Third  Female     One    Cherbourg         1\n",
      "20   Third    Male    Zero    Cherbourg         0\n",
      "21   First  Female    Zero  Southampton         1\n",
      "22   First    Male    Zero    Cherbourg         0\n",
      "23  Second  Female    Zero  Southampton         1\n",
      "24   Third  Female     One  Southampton         0\n",
      "25   Third  Female    Zero  Southampton         1\n",
      "26   Third    Male    Zero  Southampton         0\n",
      "27   Third    Male    Zero  Southampton         1\n",
      "28   Third    Male    Zero  Southampton         0\n",
      "29   Third  Female     One   Queenstown         1\n",
      "30   Third  Female     Two  Southampton         0\n",
      "31   First  Female    Zero    Cherbourg         1\n",
      "32   Third    Male     Two  Southampton         0\n",
      "33   First  Female    Zero  Southampton         1\n",
      "34   First    Male     One    Cherbourg         0\n",
      "35   First  Female    Zero  Southampton         1\n",
      "36   First    Male     One  Southampton         0\n",
      "37   Third  Female     One   Queenstown         1\n",
      "38   Third  Female     One  Southampton         0\n",
      "39  Second  Female     One  Southampton         1\n",
      "40  Second  Female     One  Southampton         0\n",
      "41   Third  Female    Zero   Queenstown         1\n",
      "42   Third    Male    Zero    Cherbourg         0\n",
      "43   First  Female    Zero    Cherbourg         1\n",
      "44   Third    Male   Three  Southampton         0\n",
      "45   Third  Female     One  Southampton         1\n",
      "46   Third    Male    Zero  Southampton         0\n",
      "47   Third    Male    Zero  Southampton         1\n",
      "48   Third    Male     One  Southampton         0\n",
      "49  Second  Female    Zero  Southampton         1\n",
      "50   First    Male   Three  Southampton         0\n",
      "51   Third    Male    Zero  Southampton         1\n",
      "52   Third  Female     One  Southampton         0\n",
      "53  Second  Female    Zero  Southampton         1\n",
      "54   Third  Female   Three  Southampton         0\n",
      "55   Third  Female    Zero  Southampton         1\n",
      "56   Third  Female    Zero  Southampton         0\n",
      "57   Third  Female     One  Southampton         1\n",
      "58   Third    Male    Zero    Cherbourg         0\n",
      "59   Third    Male    Zero  Southampton         1\n",
      "60  Second    Male    Zero  Southampton         0\n",
      "61   First  Female     One  Southampton         1\n",
      "62   Third    Male   Three   Queenstown         0\n",
      "63   Third  Female    Zero   Queenstown         1\n",
      "64  Second  Female    Zero  Southampton         0\n",
      "65   Third  Female    Zero    Cherbourg         1\n",
      "66   Third    Male    Zero  Southampton         0\n",
      "67  Second    Male    Zero  Southampton         1\n",
      "68   Third    Male    Zero  Southampton         0\n",
      "69   First    Male    Zero  Southampton         1\n",
      "70   Third    Male    Zero  Southampton         0\n",
      "71  Second    Male     Two  Southampton         1\n",
      "72   Third    Male    Zero    Cherbourg         0\n",
      "73   Third  Female    Zero  Southampton         1\n",
      "74   Third  Female    Zero  Southampton         0\n",
      "75   First  Female     One  Southampton         1\n",
      "76   Third    Male     One  Southampton         0\n",
      "77  Second  Female    Zero  Southampton         1\n",
      "78   Third    Male    Zero  Southampton         0\n",
      "79   Third  Female     Two  Southampton         1\n",
      "80   Third    Male     Two  Southampton         0\n",
      "81   Third  Female    Zero  Southampton         1\n",
      "82   Third    Male    Zero  Southampton         0\n",
      "83   First    Male     One  Southampton         1\n",
      "84  Second    Male    Zero  Southampton         0\n",
      "85   Third  Female     One   Queenstown         1\n",
      "86  Second    Male    Zero  Southampton         0\n",
      "87   First  Female     One  Southampton         1\n",
      "88   Third    Male    Zero  Southampton         0\n",
      "89  Second  Female    Zero  Southampton         1\n",
      "90  Second    Male    Zero  Southampton         0\n",
      "91  Second  Female    Zero  Southampton         1\n",
      "92   Third    Male    Zero    Cherbourg         0\n",
      "93   First    Male     One  Southampton         1\n",
      "94   First    Male     One  Southampton         0\n",
      "95   Third    Male     One    Cherbourg         1\n",
      "96   Third    Male     One   Queenstown         0\n",
      "97   Third    Male     One  Southampton         1\n",
      "98  Second    Male     One  Southampton         0\n",
      "99   Third    Male     One  Southampton         1\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Purpose of this section:\n",
    "-------------------------\n",
    "This part of the code applies Label Encoding to the target/output variable \n",
    "(\"Survived\") in the dataset. The categorical values (\"Yes\", \"No\") are \n",
    "converted into numerical values (e.g., 1 and 0) that can be used by \n",
    "machine learning algorithms.\n",
    "\n",
    "Steps:\n",
    "1. Make copies of the dataset for comparison (original vs. encoded).\n",
    "2. Encode the \"Survived\" column using the trained LabelEncoder.\n",
    "3. Display the original and encoded values side by side.\n",
    "4. Print both original and encoded datasets for clarity.\n",
    "5. Save the encoded dataset into a new CSV file.\n",
    "\"\"\"\n",
    "\n",
    "# Create copies of the dataset (one for encoded output, one to keep original)\n",
    "sample_data_encoded_output = sample_data.copy()\n",
    "original_sample_data = sample_data.copy()\n",
    "\n",
    "# Transform \"Survived\" (categorical → numeric) using the trained LabelEncoder\n",
    "print(\"\\n\\nSurvived Attribute After Label Encoding:\")\n",
    "print(\"========================================\\n\")\n",
    "sample_data[\"encoded_survived\"] = survived_label_encoder.transform(sample_data['Survived'])\n",
    "\n",
    "# Show original \"Survived\" values and their numeric encodings\n",
    "print(sample_data[[\"Survived\", \"encoded_survived\"]])\n",
    "\n",
    "# Replace original categorical columns with encoded values for the output dataset\n",
    "sample_data_encoded_output[['PClass', 'Gender', 'Sibling', 'Embarked', 'Survived']] = \\\n",
    "    sample_data[['PClass', 'Gender', 'Sibling', 'Embarked', 'encoded_survived']]\n",
    "\n",
    "# Print the original dataset\n",
    "print(\"\\n\\nOriginal Sample Data:\")\n",
    "print(\"=====================\\n\")\n",
    "print(original_sample_data)\n",
    "\n",
    "# Print the dataset after encoding the output\n",
    "print(\"\\n\\nSample Data after Label Encoding of Output:\")\n",
    "print(\"===========================================\\n\")\n",
    "print(sample_data_encoded_output)\n",
    "\n",
    "# Save the encoded dataset to a CSV file (useful for training/testing later)\n",
    "sample_data_encoded_output.to_csv(r'sample-data-encoded-output.csv', index=False, header=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4192193f-fac6-4e75-950c-17246c988033",
   "metadata": {},
   "source": [
    "#### Step 5.3: Label Encode the Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9bf80238-26dc-4787-b3c3-c5fd9059b541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "PClass Attribute After Label Encoding:\n",
      "======================================\n",
      "\n",
      "    PClass  encoded_pclass\n",
      "0    Third               2\n",
      "1   Second               1\n",
      "2    Third               2\n",
      "3    Third               2\n",
      "4    Third               2\n",
      "5    First               0\n",
      "6    Third               2\n",
      "7    Third               2\n",
      "8    First               0\n",
      "9   Second               1\n",
      "10   Third               2\n",
      "11   First               0\n",
      "12   First               0\n",
      "13  Second               1\n",
      "14  Second               1\n",
      "15   Third               2\n",
      "16   Third               2\n",
      "17   Third               2\n",
      "18   Third               2\n",
      "19   Third               2\n",
      "20   Third               2\n",
      "21   First               0\n",
      "22   First               0\n",
      "23  Second               1\n",
      "24   Third               2\n",
      "25   Third               2\n",
      "26   Third               2\n",
      "27   Third               2\n",
      "28   Third               2\n",
      "29   Third               2\n",
      "30   Third               2\n",
      "31   First               0\n",
      "32   Third               2\n",
      "33   First               0\n",
      "34   First               0\n",
      "35   First               0\n",
      "36   First               0\n",
      "37   Third               2\n",
      "38   Third               2\n",
      "39  Second               1\n",
      "40  Second               1\n",
      "41   Third               2\n",
      "42   Third               2\n",
      "43   First               0\n",
      "44   Third               2\n",
      "45   Third               2\n",
      "46   Third               2\n",
      "47   Third               2\n",
      "48   Third               2\n",
      "49  Second               1\n",
      "50   First               0\n",
      "51   Third               2\n",
      "52   Third               2\n",
      "53  Second               1\n",
      "54   Third               2\n",
      "55   Third               2\n",
      "56   Third               2\n",
      "57   Third               2\n",
      "58   Third               2\n",
      "59   Third               2\n",
      "60  Second               1\n",
      "61   First               0\n",
      "62   Third               2\n",
      "63   Third               2\n",
      "64  Second               1\n",
      "65   Third               2\n",
      "66   Third               2\n",
      "67  Second               1\n",
      "68   Third               2\n",
      "69   First               0\n",
      "70   Third               2\n",
      "71  Second               1\n",
      "72   Third               2\n",
      "73   Third               2\n",
      "74   Third               2\n",
      "75   First               0\n",
      "76   Third               2\n",
      "77  Second               1\n",
      "78   Third               2\n",
      "79   Third               2\n",
      "80   Third               2\n",
      "81   Third               2\n",
      "82   Third               2\n",
      "83   First               0\n",
      "84  Second               1\n",
      "85   Third               2\n",
      "86  Second               1\n",
      "87   First               0\n",
      "88   Third               2\n",
      "89  Second               1\n",
      "90  Second               1\n",
      "91  Second               1\n",
      "92   Third               2\n",
      "93   First               0\n",
      "94   First               0\n",
      "95   Third               2\n",
      "96   Third               2\n",
      "97   Third               2\n",
      "98  Second               1\n",
      "99   Third               2\n",
      "\n",
      "\n",
      "Gender Attribute After Label Encoding:\n",
      "======================================\n",
      "\n",
      "    Gender  encoded_gender\n",
      "0     Male               1\n",
      "1   Female               0\n",
      "2     Male               1\n",
      "3   Female               0\n",
      "4     Male               1\n",
      "5   Female               0\n",
      "6     Male               1\n",
      "7     Male               1\n",
      "8     Male               1\n",
      "9     Male               1\n",
      "10    Male               1\n",
      "11    Male               1\n",
      "12    Male               1\n",
      "13  Female               0\n",
      "14    Male               1\n",
      "15    Male               1\n",
      "16    Male               1\n",
      "17    Male               1\n",
      "18    Male               1\n",
      "19  Female               0\n",
      "20    Male               1\n",
      "21  Female               0\n",
      "22    Male               1\n",
      "23  Female               0\n",
      "24  Female               0\n",
      "25  Female               0\n",
      "26    Male               1\n",
      "27    Male               1\n",
      "28    Male               1\n",
      "29  Female               0\n",
      "30  Female               0\n",
      "31  Female               0\n",
      "32    Male               1\n",
      "33  Female               0\n",
      "34    Male               1\n",
      "35  Female               0\n",
      "36    Male               1\n",
      "37  Female               0\n",
      "38  Female               0\n",
      "39  Female               0\n",
      "40  Female               0\n",
      "41  Female               0\n",
      "42    Male               1\n",
      "43  Female               0\n",
      "44    Male               1\n",
      "45  Female               0\n",
      "46    Male               1\n",
      "47    Male               1\n",
      "48    Male               1\n",
      "49  Female               0\n",
      "50    Male               1\n",
      "51    Male               1\n",
      "52  Female               0\n",
      "53  Female               0\n",
      "54  Female               0\n",
      "55  Female               0\n",
      "56  Female               0\n",
      "57  Female               0\n",
      "58    Male               1\n",
      "59    Male               1\n",
      "60    Male               1\n",
      "61  Female               0\n",
      "62    Male               1\n",
      "63  Female               0\n",
      "64  Female               0\n",
      "65  Female               0\n",
      "66    Male               1\n",
      "67    Male               1\n",
      "68    Male               1\n",
      "69    Male               1\n",
      "70    Male               1\n",
      "71    Male               1\n",
      "72    Male               1\n",
      "73  Female               0\n",
      "74  Female               0\n",
      "75  Female               0\n",
      "76    Male               1\n",
      "77  Female               0\n",
      "78    Male               1\n",
      "79  Female               0\n",
      "80    Male               1\n",
      "81  Female               0\n",
      "82    Male               1\n",
      "83    Male               1\n",
      "84    Male               1\n",
      "85  Female               0\n",
      "86    Male               1\n",
      "87  Female               0\n",
      "88    Male               1\n",
      "89  Female               0\n",
      "90    Male               1\n",
      "91  Female               0\n",
      "92    Male               1\n",
      "93    Male               1\n",
      "94    Male               1\n",
      "95    Male               1\n",
      "96    Male               1\n",
      "97    Male               1\n",
      "98    Male               1\n",
      "99    Male               1\n",
      "\n",
      "\n",
      "Sibling Attribute After Label Encoding:\n",
      "=======================================\n",
      "\n",
      "   Sibling  encoded_sibling\n",
      "0      One                0\n",
      "1     Zero                3\n",
      "2     Zero                3\n",
      "3    Three                1\n",
      "4     Zero                3\n",
      "5    Three                1\n",
      "6     Zero                3\n",
      "7     Zero                3\n",
      "8     Zero                3\n",
      "9     Zero                3\n",
      "10     One                0\n",
      "11    Zero                3\n",
      "12    Zero                3\n",
      "13    Zero                3\n",
      "14    Zero                3\n",
      "15     One                0\n",
      "16     Two                2\n",
      "17    Zero                3\n",
      "18    Zero                3\n",
      "19     One                0\n",
      "20    Zero                3\n",
      "21    Zero                3\n",
      "22    Zero                3\n",
      "23    Zero                3\n",
      "24     One                0\n",
      "25    Zero                3\n",
      "26    Zero                3\n",
      "27    Zero                3\n",
      "28    Zero                3\n",
      "29     One                0\n",
      "30     Two                2\n",
      "31    Zero                3\n",
      "32     Two                2\n",
      "33    Zero                3\n",
      "34     One                0\n",
      "35    Zero                3\n",
      "36     One                0\n",
      "37     One                0\n",
      "38     One                0\n",
      "39     One                0\n",
      "40     One                0\n",
      "41    Zero                3\n",
      "42    Zero                3\n",
      "43    Zero                3\n",
      "44   Three                1\n",
      "45     One                0\n",
      "46    Zero                3\n",
      "47    Zero                3\n",
      "48     One                0\n",
      "49    Zero                3\n",
      "50   Three                1\n",
      "51    Zero                3\n",
      "52     One                0\n",
      "53    Zero                3\n",
      "54   Three                1\n",
      "55    Zero                3\n",
      "56    Zero                3\n",
      "57     One                0\n",
      "58    Zero                3\n",
      "59    Zero                3\n",
      "60    Zero                3\n",
      "61     One                0\n",
      "62   Three                1\n",
      "63    Zero                3\n",
      "64    Zero                3\n",
      "65    Zero                3\n",
      "66    Zero                3\n",
      "67    Zero                3\n",
      "68    Zero                3\n",
      "69    Zero                3\n",
      "70    Zero                3\n",
      "71     Two                2\n",
      "72    Zero                3\n",
      "73    Zero                3\n",
      "74    Zero                3\n",
      "75     One                0\n",
      "76     One                0\n",
      "77    Zero                3\n",
      "78    Zero                3\n",
      "79     Two                2\n",
      "80     Two                2\n",
      "81    Zero                3\n",
      "82    Zero                3\n",
      "83     One                0\n",
      "84    Zero                3\n",
      "85     One                0\n",
      "86    Zero                3\n",
      "87     One                0\n",
      "88    Zero                3\n",
      "89    Zero                3\n",
      "90    Zero                3\n",
      "91    Zero                3\n",
      "92    Zero                3\n",
      "93     One                0\n",
      "94     One                0\n",
      "95     One                0\n",
      "96     One                0\n",
      "97     One                0\n",
      "98     One                0\n",
      "99     One                0\n",
      "\n",
      "\n",
      "Embarked Attribute After Label Encoding:\n",
      "========================================\n",
      "\n",
      "       Embarked  encoded_embarked\n",
      "0   Southampton                 2\n",
      "1   Southampton                 2\n",
      "2   Southampton                 2\n",
      "3   Southampton                 2\n",
      "4    Queenstown                 1\n",
      "5   Southampton                 2\n",
      "6   Southampton                 2\n",
      "7   Southampton                 2\n",
      "8   Southampton                 2\n",
      "9   Southampton                 2\n",
      "10   Queenstown                 1\n",
      "11    Cherbourg                 0\n",
      "12    Cherbourg                 0\n",
      "13  Southampton                 2\n",
      "14  Southampton                 2\n",
      "15    Cherbourg                 0\n",
      "16    Cherbourg                 0\n",
      "17  Southampton                 2\n",
      "18  Southampton                 2\n",
      "19    Cherbourg                 0\n",
      "20    Cherbourg                 0\n",
      "21  Southampton                 2\n",
      "22    Cherbourg                 0\n",
      "23  Southampton                 2\n",
      "24  Southampton                 2\n",
      "25  Southampton                 2\n",
      "26  Southampton                 2\n",
      "27  Southampton                 2\n",
      "28  Southampton                 2\n",
      "29   Queenstown                 1\n",
      "30  Southampton                 2\n",
      "31    Cherbourg                 0\n",
      "32  Southampton                 2\n",
      "33  Southampton                 2\n",
      "34    Cherbourg                 0\n",
      "35  Southampton                 2\n",
      "36  Southampton                 2\n",
      "37   Queenstown                 1\n",
      "38  Southampton                 2\n",
      "39  Southampton                 2\n",
      "40  Southampton                 2\n",
      "41   Queenstown                 1\n",
      "42    Cherbourg                 0\n",
      "43    Cherbourg                 0\n",
      "44  Southampton                 2\n",
      "45  Southampton                 2\n",
      "46  Southampton                 2\n",
      "47  Southampton                 2\n",
      "48  Southampton                 2\n",
      "49  Southampton                 2\n",
      "50  Southampton                 2\n",
      "51  Southampton                 2\n",
      "52  Southampton                 2\n",
      "53  Southampton                 2\n",
      "54  Southampton                 2\n",
      "55  Southampton                 2\n",
      "56  Southampton                 2\n",
      "57  Southampton                 2\n",
      "58    Cherbourg                 0\n",
      "59  Southampton                 2\n",
      "60  Southampton                 2\n",
      "61  Southampton                 2\n",
      "62   Queenstown                 1\n",
      "63   Queenstown                 1\n",
      "64  Southampton                 2\n",
      "65    Cherbourg                 0\n",
      "66  Southampton                 2\n",
      "67  Southampton                 2\n",
      "68  Southampton                 2\n",
      "69  Southampton                 2\n",
      "70  Southampton                 2\n",
      "71  Southampton                 2\n",
      "72    Cherbourg                 0\n",
      "73  Southampton                 2\n",
      "74  Southampton                 2\n",
      "75  Southampton                 2\n",
      "76  Southampton                 2\n",
      "77  Southampton                 2\n",
      "78  Southampton                 2\n",
      "79  Southampton                 2\n",
      "80  Southampton                 2\n",
      "81  Southampton                 2\n",
      "82  Southampton                 2\n",
      "83  Southampton                 2\n",
      "84  Southampton                 2\n",
      "85   Queenstown                 1\n",
      "86  Southampton                 2\n",
      "87  Southampton                 2\n",
      "88  Southampton                 2\n",
      "89  Southampton                 2\n",
      "90  Southampton                 2\n",
      "91  Southampton                 2\n",
      "92    Cherbourg                 0\n",
      "93  Southampton                 2\n",
      "94  Southampton                 2\n",
      "95    Cherbourg                 0\n",
      "96   Queenstown                 1\n",
      "97  Southampton                 2\n",
      "98  Southampton                 2\n",
      "99  Southampton                 2\n",
      "\n",
      "\n",
      "Original Sample Data:\n",
      "=====================\n",
      "\n",
      "    PClass  Gender Sibling     Embarked Survived\n",
      "0    Third    Male     One  Southampton       No\n",
      "1   Second  Female    Zero  Southampton      Yes\n",
      "2    Third    Male    Zero  Southampton       No\n",
      "3    Third  Female   Three  Southampton      Yes\n",
      "4    Third    Male    Zero   Queenstown       No\n",
      "5    First  Female   Three  Southampton      Yes\n",
      "6    Third    Male    Zero  Southampton       No\n",
      "7    Third    Male    Zero  Southampton      Yes\n",
      "8    First    Male    Zero  Southampton       No\n",
      "9   Second    Male    Zero  Southampton      Yes\n",
      "10   Third    Male     One   Queenstown       No\n",
      "11   First    Male    Zero    Cherbourg      Yes\n",
      "12   First    Male    Zero    Cherbourg       No\n",
      "13  Second  Female    Zero  Southampton      Yes\n",
      "14  Second    Male    Zero  Southampton       No\n",
      "15   Third    Male     One    Cherbourg      Yes\n",
      "16   Third    Male     Two    Cherbourg       No\n",
      "17   Third    Male    Zero  Southampton      Yes\n",
      "18   Third    Male    Zero  Southampton       No\n",
      "19   Third  Female     One    Cherbourg      Yes\n",
      "20   Third    Male    Zero    Cherbourg       No\n",
      "21   First  Female    Zero  Southampton      Yes\n",
      "22   First    Male    Zero    Cherbourg       No\n",
      "23  Second  Female    Zero  Southampton      Yes\n",
      "24   Third  Female     One  Southampton       No\n",
      "25   Third  Female    Zero  Southampton      Yes\n",
      "26   Third    Male    Zero  Southampton       No\n",
      "27   Third    Male    Zero  Southampton      Yes\n",
      "28   Third    Male    Zero  Southampton       No\n",
      "29   Third  Female     One   Queenstown      Yes\n",
      "30   Third  Female     Two  Southampton       No\n",
      "31   First  Female    Zero    Cherbourg      Yes\n",
      "32   Third    Male     Two  Southampton       No\n",
      "33   First  Female    Zero  Southampton      Yes\n",
      "34   First    Male     One    Cherbourg       No\n",
      "35   First  Female    Zero  Southampton      Yes\n",
      "36   First    Male     One  Southampton       No\n",
      "37   Third  Female     One   Queenstown      Yes\n",
      "38   Third  Female     One  Southampton       No\n",
      "39  Second  Female     One  Southampton      Yes\n",
      "40  Second  Female     One  Southampton       No\n",
      "41   Third  Female    Zero   Queenstown      Yes\n",
      "42   Third    Male    Zero    Cherbourg       No\n",
      "43   First  Female    Zero    Cherbourg      Yes\n",
      "44   Third    Male   Three  Southampton       No\n",
      "45   Third  Female     One  Southampton      Yes\n",
      "46   Third    Male    Zero  Southampton       No\n",
      "47   Third    Male    Zero  Southampton      Yes\n",
      "48   Third    Male     One  Southampton       No\n",
      "49  Second  Female    Zero  Southampton      Yes\n",
      "50   First    Male   Three  Southampton       No\n",
      "51   Third    Male    Zero  Southampton      Yes\n",
      "52   Third  Female     One  Southampton       No\n",
      "53  Second  Female    Zero  Southampton      Yes\n",
      "54   Third  Female   Three  Southampton       No\n",
      "55   Third  Female    Zero  Southampton      Yes\n",
      "56   Third  Female    Zero  Southampton       No\n",
      "57   Third  Female     One  Southampton      Yes\n",
      "58   Third    Male    Zero    Cherbourg       No\n",
      "59   Third    Male    Zero  Southampton      Yes\n",
      "60  Second    Male    Zero  Southampton       No\n",
      "61   First  Female     One  Southampton      Yes\n",
      "62   Third    Male   Three   Queenstown       No\n",
      "63   Third  Female    Zero   Queenstown      Yes\n",
      "64  Second  Female    Zero  Southampton       No\n",
      "65   Third  Female    Zero    Cherbourg      Yes\n",
      "66   Third    Male    Zero  Southampton       No\n",
      "67  Second    Male    Zero  Southampton      Yes\n",
      "68   Third    Male    Zero  Southampton       No\n",
      "69   First    Male    Zero  Southampton      Yes\n",
      "70   Third    Male    Zero  Southampton       No\n",
      "71  Second    Male     Two  Southampton      Yes\n",
      "72   Third    Male    Zero    Cherbourg       No\n",
      "73   Third  Female    Zero  Southampton      Yes\n",
      "74   Third  Female    Zero  Southampton       No\n",
      "75   First  Female     One  Southampton      Yes\n",
      "76   Third    Male     One  Southampton       No\n",
      "77  Second  Female    Zero  Southampton      Yes\n",
      "78   Third    Male    Zero  Southampton       No\n",
      "79   Third  Female     Two  Southampton      Yes\n",
      "80   Third    Male     Two  Southampton       No\n",
      "81   Third  Female    Zero  Southampton      Yes\n",
      "82   Third    Male    Zero  Southampton       No\n",
      "83   First    Male     One  Southampton      Yes\n",
      "84  Second    Male    Zero  Southampton       No\n",
      "85   Third  Female     One   Queenstown      Yes\n",
      "86  Second    Male    Zero  Southampton       No\n",
      "87   First  Female     One  Southampton      Yes\n",
      "88   Third    Male    Zero  Southampton       No\n",
      "89  Second  Female    Zero  Southampton      Yes\n",
      "90  Second    Male    Zero  Southampton       No\n",
      "91  Second  Female    Zero  Southampton      Yes\n",
      "92   Third    Male    Zero    Cherbourg       No\n",
      "93   First    Male     One  Southampton      Yes\n",
      "94   First    Male     One  Southampton       No\n",
      "95   Third    Male     One    Cherbourg      Yes\n",
      "96   Third    Male     One   Queenstown       No\n",
      "97   Third    Male     One  Southampton      Yes\n",
      "98  Second    Male     One  Southampton       No\n",
      "99   Third    Male     One  Southampton      Yes\n",
      "\n",
      "\n",
      "Sample Data after Label Encoding:\n",
      "=================================\n",
      "\n",
      "    PClass  Gender  Sibling  Embarked  Survived\n",
      "0        2       1        0         2         0\n",
      "1        1       0        3         2         1\n",
      "2        2       1        3         2         0\n",
      "3        2       0        1         2         1\n",
      "4        2       1        3         1         0\n",
      "5        0       0        1         2         1\n",
      "6        2       1        3         2         0\n",
      "7        2       1        3         2         1\n",
      "8        0       1        3         2         0\n",
      "9        1       1        3         2         1\n",
      "10       2       1        0         1         0\n",
      "11       0       1        3         0         1\n",
      "12       0       1        3         0         0\n",
      "13       1       0        3         2         1\n",
      "14       1       1        3         2         0\n",
      "15       2       1        0         0         1\n",
      "16       2       1        2         0         0\n",
      "17       2       1        3         2         1\n",
      "18       2       1        3         2         0\n",
      "19       2       0        0         0         1\n",
      "20       2       1        3         0         0\n",
      "21       0       0        3         2         1\n",
      "22       0       1        3         0         0\n",
      "23       1       0        3         2         1\n",
      "24       2       0        0         2         0\n",
      "25       2       0        3         2         1\n",
      "26       2       1        3         2         0\n",
      "27       2       1        3         2         1\n",
      "28       2       1        3         2         0\n",
      "29       2       0        0         1         1\n",
      "30       2       0        2         2         0\n",
      "31       0       0        3         0         1\n",
      "32       2       1        2         2         0\n",
      "33       0       0        3         2         1\n",
      "34       0       1        0         0         0\n",
      "35       0       0        3         2         1\n",
      "36       0       1        0         2         0\n",
      "37       2       0        0         1         1\n",
      "38       2       0        0         2         0\n",
      "39       1       0        0         2         1\n",
      "40       1       0        0         2         0\n",
      "41       2       0        3         1         1\n",
      "42       2       1        3         0         0\n",
      "43       0       0        3         0         1\n",
      "44       2       1        1         2         0\n",
      "45       2       0        0         2         1\n",
      "46       2       1        3         2         0\n",
      "47       2       1        3         2         1\n",
      "48       2       1        0         2         0\n",
      "49       1       0        3         2         1\n",
      "50       0       1        1         2         0\n",
      "51       2       1        3         2         1\n",
      "52       2       0        0         2         0\n",
      "53       1       0        3         2         1\n",
      "54       2       0        1         2         0\n",
      "55       2       0        3         2         1\n",
      "56       2       0        3         2         0\n",
      "57       2       0        0         2         1\n",
      "58       2       1        3         0         0\n",
      "59       2       1        3         2         1\n",
      "60       1       1        3         2         0\n",
      "61       0       0        0         2         1\n",
      "62       2       1        1         1         0\n",
      "63       2       0        3         1         1\n",
      "64       1       0        3         2         0\n",
      "65       2       0        3         0         1\n",
      "66       2       1        3         2         0\n",
      "67       1       1        3         2         1\n",
      "68       2       1        3         2         0\n",
      "69       0       1        3         2         1\n",
      "70       2       1        3         2         0\n",
      "71       1       1        2         2         1\n",
      "72       2       1        3         0         0\n",
      "73       2       0        3         2         1\n",
      "74       2       0        3         2         0\n",
      "75       0       0        0         2         1\n",
      "76       2       1        0         2         0\n",
      "77       1       0        3         2         1\n",
      "78       2       1        3         2         0\n",
      "79       2       0        2         2         1\n",
      "80       2       1        2         2         0\n",
      "81       2       0        3         2         1\n",
      "82       2       1        3         2         0\n",
      "83       0       1        0         2         1\n",
      "84       1       1        3         2         0\n",
      "85       2       0        0         1         1\n",
      "86       1       1        3         2         0\n",
      "87       0       0        0         2         1\n",
      "88       2       1        3         2         0\n",
      "89       1       0        3         2         1\n",
      "90       1       1        3         2         0\n",
      "91       1       0        3         2         1\n",
      "92       2       1        3         0         0\n",
      "93       0       1        0         2         1\n",
      "94       0       1        0         2         0\n",
      "95       2       1        0         0         1\n",
      "96       2       1        0         1         0\n",
      "97       2       1        0         2         1\n",
      "98       1       1        0         2         0\n",
      "99       2       1        0         2         1\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Purpose of this section:\n",
    "-------------------------\n",
    "This part of the code applies Label Encoding to the input features \n",
    "(\"PClass\", \"Gender\", \"Sibling\", \"Embarked\"). Each categorical value \n",
    "is converted into a numeric value so that machine learning models \n",
    "can process them.\n",
    "\n",
    "Steps:\n",
    "1. Make copies of the dataset to preserve original values.\n",
    "2. Encode each input attribute (PClass, Gender, Sibling, Embarked).\n",
    "3. Display the original values alongside their numeric encodings.\n",
    "4. Replace categorical columns with their encoded versions.\n",
    "5. Print original vs. encoded datasets for clarity.\n",
    "6. Save the fully encoded dataset into a CSV file.\n",
    "\"\"\"\n",
    "\n",
    "# Create copies of the dataset (to keep original values safe)\n",
    "sample_data_encoded = sample_data_encoded_output.copy()\n",
    "sample_data_encoded_output_orignal = sample_data_encoded_output.copy()\n",
    "\n",
    "# Encode \"PClass\" attribute\n",
    "print(\"\\n\\nPClass Attribute After Label Encoding:\")\n",
    "print(\"======================================\\n\")\n",
    "sample_data_encoded_output[\"encoded_pclass\"] = pclass_label_encoder.transform(sample_data_encoded_output['PClass'])\n",
    "print(sample_data_encoded_output[[\"PClass\", \"encoded_pclass\"]])\n",
    "\n",
    "# Encode \"Gender\" attribute\n",
    "print(\"\\n\\nGender Attribute After Label Encoding:\")\n",
    "print(\"======================================\\n\")\n",
    "sample_data_encoded_output[\"encoded_gender\"] = gender_label_encoder.transform(sample_data_encoded_output['Gender'])\n",
    "print(sample_data_encoded_output[[\"Gender\", \"encoded_gender\"]])\n",
    "\n",
    "# Encode \"Sibling\" attribute\n",
    "print(\"\\n\\nSibling Attribute After Label Encoding:\")\n",
    "print(\"=======================================\\n\")\n",
    "sample_data_encoded_output[\"encoded_sibling\"] = sibling_label_encoder.transform(sample_data_encoded_output['Sibling'])\n",
    "print(sample_data_encoded_output[[\"Sibling\", \"encoded_sibling\"]])\n",
    "\n",
    "# Encode \"Embarked\" attribute\n",
    "print(\"\\n\\nEmbarked Attribute After Label Encoding:\")\n",
    "print(\"========================================\\n\")\n",
    "sample_data_encoded_output[\"encoded_embarked\"] = embarked_label_encoder.transform(sample_data_encoded_output['Embarked'])\n",
    "print(sample_data_encoded_output[[\"Embarked\", \"encoded_embarked\"]])\n",
    "\n",
    "# Replace categorical columns with encoded values in the dataset\n",
    "sample_data_encoded[['PClass', 'Gender', 'Sibling', 'Embarked', 'Survived']] = \\\n",
    "    sample_data_encoded_output[['encoded_pclass', 'encoded_gender', 'encoded_sibling', 'encoded_embarked', 'Survived']]\n",
    "\n",
    "# Print original dataset (with text categories)\n",
    "print(\"\\n\\nOriginal Sample Data:\")\n",
    "print(\"=====================\\n\")\n",
    "print(original_sample_data)\n",
    "\n",
    "# Print encoded dataset (with numeric values instead of categories)\n",
    "print(\"\\n\\nSample Data after Label Encoding:\")\n",
    "print(\"=================================\\n\")\n",
    "print(sample_data_encoded)\n",
    "\n",
    "# Save the encoded dataset to a new CSV file\n",
    "sample_data_encoded.to_csv(r'sample-data-encoded.csv', index=False, header=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffe9fd8-9bdb-4e00-a0d2-a16427df2d63",
   "metadata": {},
   "source": [
    "### Step 6: Execute the Training Phase\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fa3f22-90cb-4f99-beb2-cf8b4390a6cb",
   "metadata": {},
   "source": [
    "#### Step 6.1: Splitting Sample Data into Training Data and Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f25641b3-eb5f-4a55-bea6-1f6985a1c48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training Data:\n",
      "==============\n",
      "\n",
      "    PClass  Gender  Sibling  Embarked  Survived\n",
      "0        2       1        0         2         0\n",
      "1        1       0        3         2         1\n",
      "2        2       1        3         2         0\n",
      "3        2       0        1         2         1\n",
      "4        2       1        3         1         0\n",
      "5        0       0        1         2         1\n",
      "6        2       1        3         2         0\n",
      "7        2       1        3         2         1\n",
      "8        0       1        3         2         0\n",
      "9        1       1        3         2         1\n",
      "10       2       1        0         1         0\n",
      "11       0       1        3         0         1\n",
      "12       0       1        3         0         0\n",
      "13       1       0        3         2         1\n",
      "14       1       1        3         2         0\n",
      "15       2       1        0         0         1\n",
      "16       2       1        2         0         0\n",
      "17       2       1        3         2         1\n",
      "18       2       1        3         2         0\n",
      "19       2       0        0         0         1\n",
      "20       2       1        3         0         0\n",
      "21       0       0        3         2         1\n",
      "22       0       1        3         0         0\n",
      "23       1       0        3         2         1\n",
      "24       2       0        0         2         0\n",
      "25       2       0        3         2         1\n",
      "26       2       1        3         2         0\n",
      "27       2       1        3         2         1\n",
      "28       2       1        3         2         0\n",
      "29       2       0        0         1         1\n",
      "30       2       0        2         2         0\n",
      "31       0       0        3         0         1\n",
      "32       2       1        2         2         0\n",
      "33       0       0        3         2         1\n",
      "34       0       1        0         0         0\n",
      "35       0       0        3         2         1\n",
      "36       0       1        0         2         0\n",
      "37       2       0        0         1         1\n",
      "38       2       0        0         2         0\n",
      "39       1       0        0         2         1\n",
      "40       1       0        0         2         0\n",
      "41       2       0        3         1         1\n",
      "42       2       1        3         0         0\n",
      "43       0       0        3         0         1\n",
      "44       2       1        1         2         0\n",
      "45       2       0        0         2         1\n",
      "46       2       1        3         2         0\n",
      "47       2       1        3         2         1\n",
      "48       2       1        0         2         0\n",
      "49       1       0        3         2         1\n",
      "50       0       1        1         2         0\n",
      "51       2       1        3         2         1\n",
      "52       2       0        0         2         0\n",
      "53       1       0        3         2         1\n",
      "54       2       0        1         2         0\n",
      "55       2       0        3         2         1\n",
      "56       2       0        3         2         0\n",
      "57       2       0        0         2         1\n",
      "58       2       1        3         0         0\n",
      "59       2       1        3         2         1\n",
      "60       1       1        3         2         0\n",
      "61       0       0        0         2         1\n",
      "62       2       1        1         1         0\n",
      "63       2       0        3         1         1\n",
      "64       1       0        3         2         0\n",
      "65       2       0        3         0         1\n",
      "66       2       1        3         2         0\n",
      "67       1       1        3         2         1\n",
      "68       2       1        3         2         0\n",
      "69       0       1        3         2         1\n",
      "70       2       1        3         2         0\n",
      "71       1       1        2         2         1\n",
      "72       2       1        3         0         0\n",
      "73       2       0        3         2         1\n",
      "74       2       0        3         2         0\n",
      "75       0       0        0         2         1\n",
      "76       2       1        0         2         0\n",
      "77       1       0        3         2         1\n",
      "78       2       1        3         2         0\n",
      "79       2       0        2         2         1\n",
      "\n",
      "\n",
      "Testing Data:\n",
      "==============\n",
      "\n",
      "    PClass  Gender  Sibling  Embarked  Survived\n",
      "80       2       1        2         2         0\n",
      "81       2       0        3         2         1\n",
      "82       2       1        3         2         0\n",
      "83       0       1        0         2         1\n",
      "84       1       1        3         2         0\n",
      "85       2       0        0         1         1\n",
      "86       1       1        3         2         0\n",
      "87       0       0        0         2         1\n",
      "88       2       1        3         2         0\n",
      "89       1       0        3         2         1\n",
      "90       1       1        3         2         0\n",
      "91       1       0        3         2         1\n",
      "92       2       1        3         0         0\n",
      "93       0       1        0         2         1\n",
      "94       0       1        0         2         0\n",
      "95       2       1        0         0         1\n",
      "96       2       1        0         1         0\n",
      "97       2       1        0         2         1\n",
      "98       1       1        0         2         0\n",
      "99       2       1        0         2         1\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Purpose of this section:\n",
    "-------------------------\n",
    "This part of the code splits the dataset into Training Data and Testing Data.\n",
    "- Training Data is used to teach the machine learning model.\n",
    "- Testing Data is used to check how well the model performs on unseen data.\n",
    "\n",
    "Steps:\n",
    "1. Use train_test_split() to split the dataset into training (80%) and testing (20%).\n",
    "2. Save the training and testing sets as separate CSV files.\n",
    "3. Print both datasets to verify the split.\n",
    "\"\"\"\n",
    "\n",
    "# Split dataset into training (80%) and testing (20%)\n",
    "# random_state=0 ensures reproducibility (same split every time)\n",
    "# shuffle=False keeps the original order of rows (no shuffling before splitting)\n",
    "training_data_encoded, testing_data_encoded = train_test_split(\n",
    "    sample_data_encoded,\n",
    "    test_size=0.2,\n",
    "    random_state=0,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Save the training and testing datasets to CSV files\n",
    "training_data_encoded.to_csv(r'training-data-encoded.csv', index=False, header=True)\n",
    "testing_data_encoded.to_csv(r'testing-data-encoded.csv', index=False, header=True)\n",
    "\n",
    "# Print training dataset\n",
    "print(\"\\n\\nTraining Data:\")\n",
    "print(\"==============\\n\")\n",
    "print(training_data_encoded)\n",
    "\n",
    "# Print testing dataset\n",
    "print(\"\\n\\nTesting Data:\")\n",
    "print(\"==============\\n\")\n",
    "print(testing_data_encoded)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cfc320-0a86-44c2-a2ef-877f16c589a1",
   "metadata": {},
   "source": [
    "### Step 6.2: Splitting Input Vectors and Outputs / Labels of Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6d2de91a-8d2d-4cde-b902-aea5a1b69c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Inputs Vectors (Feature Vectors) of Training Data:\n",
      "==================================================\n",
      "\n",
      "    PClass  Gender  Sibling  Embarked\n",
      "0        2       1        0         2\n",
      "1        1       0        3         2\n",
      "2        2       1        3         2\n",
      "3        2       0        1         2\n",
      "4        2       1        3         1\n",
      "5        0       0        1         2\n",
      "6        2       1        3         2\n",
      "7        2       1        3         2\n",
      "8        0       1        3         2\n",
      "9        1       1        3         2\n",
      "10       2       1        0         1\n",
      "11       0       1        3         0\n",
      "12       0       1        3         0\n",
      "13       1       0        3         2\n",
      "14       1       1        3         2\n",
      "15       2       1        0         0\n",
      "16       2       1        2         0\n",
      "17       2       1        3         2\n",
      "18       2       1        3         2\n",
      "19       2       0        0         0\n",
      "20       2       1        3         0\n",
      "21       0       0        3         2\n",
      "22       0       1        3         0\n",
      "23       1       0        3         2\n",
      "24       2       0        0         2\n",
      "25       2       0        3         2\n",
      "26       2       1        3         2\n",
      "27       2       1        3         2\n",
      "28       2       1        3         2\n",
      "29       2       0        0         1\n",
      "30       2       0        2         2\n",
      "31       0       0        3         0\n",
      "32       2       1        2         2\n",
      "33       0       0        3         2\n",
      "34       0       1        0         0\n",
      "35       0       0        3         2\n",
      "36       0       1        0         2\n",
      "37       2       0        0         1\n",
      "38       2       0        0         2\n",
      "39       1       0        0         2\n",
      "40       1       0        0         2\n",
      "41       2       0        3         1\n",
      "42       2       1        3         0\n",
      "43       0       0        3         0\n",
      "44       2       1        1         2\n",
      "45       2       0        0         2\n",
      "46       2       1        3         2\n",
      "47       2       1        3         2\n",
      "48       2       1        0         2\n",
      "49       1       0        3         2\n",
      "50       0       1        1         2\n",
      "51       2       1        3         2\n",
      "52       2       0        0         2\n",
      "53       1       0        3         2\n",
      "54       2       0        1         2\n",
      "55       2       0        3         2\n",
      "56       2       0        3         2\n",
      "57       2       0        0         2\n",
      "58       2       1        3         0\n",
      "59       2       1        3         2\n",
      "60       1       1        3         2\n",
      "61       0       0        0         2\n",
      "62       2       1        1         1\n",
      "63       2       0        3         1\n",
      "64       1       0        3         2\n",
      "65       2       0        3         0\n",
      "66       2       1        3         2\n",
      "67       1       1        3         2\n",
      "68       2       1        3         2\n",
      "69       0       1        3         2\n",
      "70       2       1        3         2\n",
      "71       1       1        2         2\n",
      "72       2       1        3         0\n",
      "73       2       0        3         2\n",
      "74       2       0        3         2\n",
      "75       0       0        0         2\n",
      "76       2       1        0         2\n",
      "77       1       0        3         2\n",
      "78       2       1        3         2\n",
      "79       2       0        2         2\n",
      "\n",
      "\n",
      "Outputs/Labels of Training Data:\n",
      "================================\n",
      "\n",
      "  Survived\n",
      "0     0\n",
      "1     1\n",
      "2     0\n",
      "3     1\n",
      "4     0\n",
      "5     1\n",
      "6     0\n",
      "7     1\n",
      "8     0\n",
      "9     1\n",
      "10    0\n",
      "11    1\n",
      "12    0\n",
      "13    1\n",
      "14    0\n",
      "15    1\n",
      "16    0\n",
      "17    1\n",
      "18    0\n",
      "19    1\n",
      "20    0\n",
      "21    1\n",
      "22    0\n",
      "23    1\n",
      "24    0\n",
      "25    1\n",
      "26    0\n",
      "27    1\n",
      "28    0\n",
      "29    1\n",
      "30    0\n",
      "31    1\n",
      "32    0\n",
      "33    1\n",
      "34    0\n",
      "35    1\n",
      "36    0\n",
      "37    1\n",
      "38    0\n",
      "39    1\n",
      "40    0\n",
      "41    1\n",
      "42    0\n",
      "43    1\n",
      "44    0\n",
      "45    1\n",
      "46    0\n",
      "47    1\n",
      "48    0\n",
      "49    1\n",
      "50    0\n",
      "51    1\n",
      "52    0\n",
      "53    1\n",
      "54    0\n",
      "55    1\n",
      "56    0\n",
      "57    1\n",
      "58    0\n",
      "59    1\n",
      "60    0\n",
      "61    1\n",
      "62    0\n",
      "63    1\n",
      "64    0\n",
      "65    1\n",
      "66    0\n",
      "67    1\n",
      "68    0\n",
      "69    1\n",
      "70    0\n",
      "71    1\n",
      "72    0\n",
      "73    1\n",
      "74    0\n",
      "75    1\n",
      "76    0\n",
      "77    1\n",
      "78    0\n",
      "79    1\n",
      "Name: Survived, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Purpose of this section:\n",
    "-------------------------\n",
    "This part of the code separates the features (input vectors) and \n",
    "the labels (output values) from the training dataset.\n",
    "\n",
    "- Input Vectors (X): All columns except the last one (features like PClass, Gender, etc.)\n",
    "- Output Labels (y): The last column (Survived) which we want the model to predict.\n",
    "\n",
    "Steps:\n",
    "1. Select all columns except the last as input features.\n",
    "2. Select the last column as the target output (label).\n",
    "3. Print both to verify the split.\n",
    "\"\"\"\n",
    "\n",
    "# Extract input vectors (features) from training data\n",
    "# iloc[: , :-1] → select all rows, and all columns except the last one\n",
    "print(\"\\n\\nInputs Vectors (Feature Vectors) of Training Data:\")\n",
    "print(\"==================================================\\n\")\n",
    "input_vector_train = training_data_encoded.iloc[:, :-1]\n",
    "print(input_vector_train)\n",
    "\n",
    "# Extract output labels (target variable) from training data\n",
    "# iloc[: , -1] → select all rows, but only the last column\n",
    "print(\"\\n\\nOutputs/Labels of Training Data:\")\n",
    "print(\"================================\\n\")\n",
    "print(\"  Survived\")\n",
    "output_label_train = training_data_encoded.iloc[:, -1]\n",
    "print(output_label_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df0db1e-1bf1-421e-b65d-d917f3fc7389",
   "metadata": {},
   "source": [
    "### 6.3: Train the Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0acf03b2-9b56-415a-8e90-f52a6984ff79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training the Support Vector Classifier on Training Data\n",
      "========================================================\n",
      "\n",
      "\n",
      "Parameters and their values:\n",
      "============================\n",
      "\n",
      "SVC(gamma='auto', random_state=0)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Purpose of this section:\n",
    "-------------------------\n",
    "This part of the code trains a Support Vector Classifier (SVC) on the training data. \n",
    "The SVC is a type of machine learning model that finds the best boundary \n",
    "to separate different classes (e.g., survived vs. not survived).\n",
    "\n",
    "Steps:\n",
    "1. Initialize the SVC model with parameters.\n",
    "   - gamma='auto' : automatically sets the influence of data points.\n",
    "   - random_state=0 : ensures results are reproducible.\n",
    "2. Train (fit) the model using input features (X) and output labels (y).\n",
    "3. Print the trained model with its parameters.\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n\\nTraining the Support Vector Classifier on Training Data\")\n",
    "print(\"========================================================\\n\")\n",
    "\n",
    "# Print message for clarity\n",
    "print(\"\\nParameters and their values:\")\n",
    "print(\"============================\\n\")\n",
    "\n",
    "# Initialize the Support Vector Classifier with chosen parameters\n",
    "svc_model = svm.SVC(gamma='auto', random_state=0)\n",
    "\n",
    "# Train the model using the training data (features and labels)\n",
    "# input_vector_train = feature columns\n",
    "# output_label_train = target column (Survived)\n",
    "svc_model.fit(input_vector_train, np.ravel(output_label_train))\n",
    "\n",
    "# Print trained model details (parameters and values)\n",
    "print(svc_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be205d8-eb84-4cf2-8023-b9239f189018",
   "metadata": {},
   "source": [
    "### Step 6.4: Save the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "90c4a048-ab7e-4962-95b4-b27d90a64f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Purpose of this section:\n",
    "-------------------------\n",
    "This part of the code saves the trained Support Vector Classifier (SVC) \n",
    "model to your computer so it can be reused later without retraining.\n",
    "\n",
    "Steps:\n",
    "1. Use pickle.dump() to serialize (save) the trained model.\n",
    "2. Store it as a .pkl file on disk.\n",
    "3. The saved model can be loaded back later for predictions.\n",
    "\"\"\"\n",
    "\n",
    "# Save the trained SVC model to a file named \"svc_trained_model.pkl\"\n",
    "# 'wb' = write in binary mode\n",
    "pickle.dump(svc_model, open('svc_trained_model.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf11b54-667b-42f1-87f3-0d44ea8b4e87",
   "metadata": {},
   "source": [
    "### Step 7: Execute the Testing Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf998de1-8992-407c-a824-ed6d64667fdd",
   "metadata": {},
   "source": [
    "#### Step 7.1: Splitting Input Vectors and Outputs/Labels of Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3a8d778a-8d3e-4612-9fd0-a5ceacaf1035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Inputs Vectors (Feature Vectors) of Testing Data:\n",
      "=================================================\n",
      "\n",
      "    PClass  Gender  Sibling  Embarked\n",
      "80       2       1        2         2\n",
      "81       2       0        3         2\n",
      "82       2       1        3         2\n",
      "83       0       1        0         2\n",
      "84       1       1        3         2\n",
      "85       2       0        0         1\n",
      "86       1       1        3         2\n",
      "87       0       0        0         2\n",
      "88       2       1        3         2\n",
      "89       1       0        3         2\n",
      "90       1       1        3         2\n",
      "91       1       0        3         2\n",
      "92       2       1        3         0\n",
      "93       0       1        0         2\n",
      "94       0       1        0         2\n",
      "95       2       1        0         0\n",
      "96       2       1        0         1\n",
      "97       2       1        0         2\n",
      "98       1       1        0         2\n",
      "99       2       1        0         2\n",
      "\n",
      "\n",
      "Outputs/Labels of Testing Data:\n",
      "==============================\n",
      "\n",
      "  Survived\n",
      "80    0\n",
      "81    1\n",
      "82    0\n",
      "83    1\n",
      "84    0\n",
      "85    1\n",
      "86    0\n",
      "87    1\n",
      "88    0\n",
      "89    1\n",
      "90    0\n",
      "91    1\n",
      "92    0\n",
      "93    1\n",
      "94    0\n",
      "95    1\n",
      "96    0\n",
      "97    1\n",
      "98    0\n",
      "99    1\n",
      "Name: Survived, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Purpose of this section:\n",
    "-------------------------\n",
    "This part of the code separates the features (inputs) and the labels (outputs) \n",
    "from the testing dataset. \n",
    "\n",
    "- Input Vectors (X_test): All columns except the last one.\n",
    "- Output Labels (y_test): The last column (Survived), which we use to check \n",
    "  how well the trained model performs.\n",
    "\n",
    "Steps:\n",
    "1. Extract feature columns from testing data.\n",
    "2. Extract target/output column from testing data.\n",
    "3. Print both for verification.\n",
    "\"\"\"\n",
    "\n",
    "# Extract input vectors (features) from testing data\n",
    "# iloc[: , :-1] → select all rows, and all columns except the last one\n",
    "print(\"\\n\\nInputs Vectors (Feature Vectors) of Testing Data:\")\n",
    "print(\"=================================================\\n\")\n",
    "input_vector_test = testing_data_encoded.iloc[:, :-1]\n",
    "print(input_vector_test)\n",
    "\n",
    "# Extract output labels (target values) from testing data\n",
    "# iloc[: , -1] → select all rows, and only the last column\n",
    "print(\"\\n\\nOutputs/Labels of Testing Data:\")\n",
    "print(\"==============================\\n\")\n",
    "print(\"  Survived\")\n",
    "output_label_test = testing_data_encoded.iloc[:, -1]\n",
    "print(output_label_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6229f40c-2679-48e9-ab10-25791a72b942",
   "metadata": {},
   "source": [
    "### Step 7.2: Load the Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "64dd5bf1-c3e9-4575-ac46-d08065d40e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Purpose of this section:\n",
    "-------------------------\n",
    "This part of the code loads the previously saved Support Vector Classifier (SVC) \n",
    "model from disk into memory. By doing this, we can use the trained model for \n",
    "making predictions without retraining it from scratch.\n",
    "\n",
    "Steps:\n",
    "1. Use pickle.load() to read the model file (.pkl).\n",
    "2. Load the trained model into a Python variable.\n",
    "3. The loaded model is now ready for predictions.\n",
    "\"\"\"\n",
    "\n",
    "# Load the saved SVC model from the file \"svc_trained_model.pkl\"\n",
    "# 'rb' = read in binary mode\n",
    "model = pickle.load(open('svc_trained_model.pkl', 'rb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82842873-0a9e-4b75-a563-b0bba380acd3",
   "metadata": {},
   "source": [
    "### Step 7.3: Evaluate the Machine Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1879bc7-f3fc-4d28-b9b5-79135fa4a500",
   "metadata": {},
   "source": [
    "#### Step 7.3.1: Make Predictions with the Trained Models on Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "62db4138-6f8a-4bd6-acc5-ea60ab67d7d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Predictions Returned by svc_trained_model:\n",
      "==========================================\n",
      "\n",
      "    PClass  Gender  Sibling  Embarked  Survived  Predictions\n",
      "80       2       1        2         2         0            0\n",
      "81       2       0        3         2         1            1\n",
      "82       2       1        3         2         0            0\n",
      "83       0       1        0         2         1            0\n",
      "84       1       1        3         2         0            0\n",
      "85       2       0        0         1         1            1\n",
      "86       1       1        3         2         0            0\n",
      "87       0       0        0         2         1            1\n",
      "88       2       1        3         2         0            0\n",
      "89       1       0        3         2         1            1\n",
      "90       1       1        3         2         0            0\n",
      "91       1       0        3         2         1            1\n",
      "92       2       1        3         0         0            0\n",
      "93       0       1        0         2         1            0\n",
      "94       0       1        0         2         0            0\n",
      "95       2       1        0         0         1            1\n",
      "96       2       1        0         1         0            0\n",
      "97       2       1        0         2         1            0\n",
      "98       1       1        0         2         0            0\n",
      "99       2       1        0         2         1            0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Purpose of this section:\n",
    "-------------------------\n",
    "This part of the code evaluates the trained Support Vector Classifier (SVC) \n",
    "on the testing data. It uses the trained model to make predictions and then \n",
    "stores those predictions for further analysis.\n",
    "\n",
    "Steps:\n",
    "1. Use the trained model to predict outputs (Survived/Not Survived) for the test data.\n",
    "2. Store the predictions in the testing dataset for comparison with actual values.\n",
    "3. Save the dataset with predictions into a new CSV file.\n",
    "4. Print the predictions to verify results.\n",
    "\"\"\"\n",
    "\n",
    "# Use the trained model to predict outcomes on the testing data\n",
    "# input_vector_test = feature columns from the testing dataset\n",
    "model_predictions = model.predict(input_vector_test)\n",
    "\n",
    "# Copy the testing dataset (deep=True makes a full copy, not just references)\n",
    "testing_data_encoded.copy(deep=True)\n",
    "\n",
    "# Disable chained assignment warning (not needed for students to worry about)\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# Add predictions as a new column to the testing dataset\n",
    "testing_data_encoded[\"Predictions\"] = model_predictions\n",
    "\n",
    "# Save the predictions into a CSV file\n",
    "testing_data_encoded.to_csv(r'model-predictions.csv', index=False, header=True)\n",
    "\n",
    "# Print the predictions alongside the testing dataset\n",
    "model_predictions = testing_data_encoded\n",
    "print(\"\\n\\nPredictions Returned by svc_trained_model:\")\n",
    "print(\"==========================================\\n\")\n",
    "print(model_predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7fe8ef-e207-407c-a581-783be09e2c1b",
   "metadata": {},
   "source": [
    "### Step 7.4: Calculate the Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "83ff7b74-2b40-426f-a3d2-e30b0fe061e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Accuracy Score:\n",
      "===============\n",
      "\n",
      "0.8\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Purpose of this section:\n",
    "-------------------------\n",
    "This part of the code calculates how accurate the trained model is on the \n",
    "testing dataset. Accuracy is the ratio of correctly predicted values to the \n",
    "total number of predictions.\n",
    "\n",
    "Steps:\n",
    "1. Compare predicted values with the actual labels (Survived).\n",
    "2. Use accuracy_score() from sklearn to compute accuracy.\n",
    "3. Print the accuracy score rounded to 2 decimal places.\n",
    "\"\"\"\n",
    "\n",
    "# Calculate accuracy by comparing predictions with actual labels\n",
    "# \"Survived\"   = actual values from the testing dataset\n",
    "# \"Predictions\" = values predicted by the trained model\n",
    "model_accuracy_score = accuracy_score(\n",
    "    model_predictions[\"Survived\"],\n",
    "    model_predictions[\"Predictions\"]\n",
    ")\n",
    "\n",
    "# Print the accuracy score\n",
    "print(\"\\n\\nAccuracy Score:\")\n",
    "print(\"===============\\n\")\n",
    "print(round(model_accuracy_score, 2))  # rounded to 2 decimal places\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8492bd57-5f85-4df0-a13a-589f9f292a0b",
   "metadata": {},
   "source": [
    "### Step 8: Execute the Application Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129b6aaf-4330-4d5b-a2f6-7a88533f86bb",
   "metadata": {},
   "source": [
    "#### Step 8.1: Take Input from User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4b11c20c-4b69-4ea4-99aa-b7c5d4f796b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Please enter PClass here (First, Second, Third):  First\n",
      "\n",
      "Please enter your Gender here (Male, Female):  Male\n",
      "\n",
      "Please enter your Sibling here (Zero, One, Two, Three):  Zero\n",
      "\n",
      "Please enter Embarked here (Cherbourg, Southampton, Queenstown):  Queenstown\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Purpose of this section:\n",
    "-------------------------\n",
    "This part of the code allows the user to enter their own data \n",
    "(PClass, Gender, Sibling, Embarked). These values will later be \n",
    "encoded and used by the trained model to make a prediction.\n",
    "\n",
    "Steps:\n",
    "1. Ask the user to input their class (First, Second, Third).\n",
    "2. Ask the user to input their gender (Male, Female).\n",
    "3. Ask the user to input the number of siblings (Zero, One, Two, Three).\n",
    "4. Ask the user to input their port of embarkation \n",
    "   (Cherbourg, Southampton, Queenstown).\n",
    "\"\"\"\n",
    "\n",
    "# Take Passenger Class input from user\n",
    "pclass_input = input(\"\\nPlease enter PClass here (First, Second, Third): \").strip()\n",
    "\n",
    "# Take Gender input from user\n",
    "gender_input = input(\"\\nPlease enter your Gender here (Male, Female): \").strip()\n",
    "\n",
    "# Take Sibling count input from user\n",
    "sibling_input = input(\"\\nPlease enter your Sibling here (Zero, One, Two, Three): \").strip()\n",
    "\n",
    "# Take Port of Embarkation input from user\n",
    "embarked_input = input(\"\\nPlease enter Embarked here (Cherbourg, Southampton, Queenstown): \").strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7d7c65-8845-4670-b411-230fc64f2dab",
   "metadata": {},
   "source": [
    "### Step 8.2: Convert User Input into Feature Vector (Exactly Same as Feature Vectors of Sample Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a8f240f4-8ded-4a39-8477-be5f10f062e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "User Input Feature Vector:\n",
      "==========================\n",
      "\n",
      "  PClass Gender Sibling    Embarked\n",
      "0  First   Male    Zero  Queenstown\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Purpose of this section:\n",
    "-------------------------\n",
    "This part of the code takes the user's input (entered as text) \n",
    "and converts it into a structured feature vector (DataFrame). \n",
    "This feature vector will later be encoded into numbers so the \n",
    "trained model can use it for prediction.\n",
    "\n",
    "Steps:\n",
    "1. Create a DataFrame with the user input (PClass, Gender, Sibling, Embarked).\n",
    "2. Display the DataFrame so the user can confirm their entered values.\n",
    "\"\"\"\n",
    "\n",
    "# Convert user input into a DataFrame (feature vector)\n",
    "# Each input is placed inside a list so it becomes a row in the DataFrame\n",
    "user_input = pd.DataFrame({\n",
    "    'PClass': [pclass_input],\n",
    "    'Gender': [gender_input],\n",
    "    'Sibling': [sibling_input],\n",
    "    'Embarked': [embarked_input]\n",
    "})\n",
    "\n",
    "# Print the feature vector created from user input\n",
    "print(\"\\n\\nUser Input Feature Vector:\")\n",
    "print(\"==========================\\n\")\n",
    "print(user_input)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc49f23c-a0b4-4844-9b94-d4608a59f420",
   "metadata": {},
   "source": [
    "### Step 8.3: Label Encoding of Feature Vector (Exactly Same as Label Encoded Feature Vectors of Sample Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "df396f2e-ad2f-44be-a495-8dc81387e5fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "User Input Feature Vector:\n",
      "==========================\n",
      "\n",
      "  PClass Gender Sibling    Embarked\n",
      "0  First   Male    Zero  Queenstown\n",
      "\n",
      "\n",
      "User Input Encoded Feature Vector:\n",
      "==================================\n",
      "\n",
      "   PClass  Gender  Sibling  Embarked\n",
      "0       0       1        3         1\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Purpose of this section:\n",
    "-------------------------\n",
    "This part of the code encodes the user's input into numeric values \n",
    "using the previously trained LabelEncoders. Since machine learning \n",
    "models work with numbers (not text), this step is necessary before \n",
    "making predictions.\n",
    "\n",
    "Steps:\n",
    "1. Copy the user input DataFrame to preserve original values.\n",
    "2. Transform each categorical column (PClass, Gender, Sibling, Embarked) \n",
    "   into its numeric representation using the trained encoders.\n",
    "3. Print both the original and encoded feature vectors for comparison.\n",
    "\"\"\"\n",
    "\n",
    "# Make a copy of the user input so we keep both original and encoded versions\n",
    "unseen_data_features = user_input.copy()\n",
    "\n",
    "# Encode each attribute using its respective LabelEncoder\n",
    "unseen_data_features[\"PClass\"] = pclass_label_encoder.transform(user_input['PClass'])\n",
    "unseen_data_features[\"Gender\"] = gender_label_encoder.transform(user_input['Gender'])\n",
    "unseen_data_features[\"Sibling\"] = sibling_label_encoder.transform(user_input['Sibling'])\n",
    "unseen_data_features[\"Embarked\"] = embarked_label_encoder.transform(user_input['Embarked'])\n",
    "\n",
    "# Print the original user input feature vector\n",
    "print(\"\\n\\nUser Input Feature Vector:\")\n",
    "print(\"==========================\\n\")\n",
    "print(user_input)\n",
    "\n",
    "# Print the encoded feature vector (numeric version for the model)\n",
    "print(\"\\n\\nUser Input Encoded Feature Vector:\")\n",
    "print(\"==================================\\n\")\n",
    "print(unseen_data_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bc323d-98d2-4112-9571-66cf776754d0",
   "metadata": {},
   "source": [
    "### Step 8.4: Load the Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fa7cf138-8787-4124-a6db-5c52490aa08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Purpose of this section:\n",
    "-------------------------\n",
    "This part of the code loads the previously saved Support Vector Classifier (SVC) \n",
    "model from the `.pkl` file into memory. By doing this, we can use the trained \n",
    "model for making predictions on new (unseen) data without retraining it.\n",
    "\n",
    "Steps:\n",
    "1. Use pickle.load() to read the model file from disk.\n",
    "2. Load the trained model into a Python variable.\n",
    "3. The loaded model is ready to make predictions.\n",
    "\"\"\"\n",
    "\n",
    "# Load the trained SVC model from the file \"svc_trained_model.pkl\"\n",
    "# 'rb' = read in binary mode\n",
    "model = pickle.load(open('svc_trained_model.pkl', 'rb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4a9d11-fe82-4f38-99cc-89dbf7bc4677",
   "metadata": {},
   "source": [
    "### Step 8.5: Model Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c80ba7-af42-4cd2-b5d2-a9b2bdc13761",
   "metadata": {},
   "source": [
    "#### Step 8.5.1: Apply Model on the Label Encoded Feature Vector of unseen instance and return Prediction to the User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c1ee965e-12fd-427f-a97d-1fd3003256c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+\n",
      "|        ** Prediction **        |\n",
      "+--------------------------------+\n",
      "|            SURVIVED            |\n",
      "+--------------------------------+\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Purpose of this section:\n",
    "-------------------------\n",
    "This part of the code uses the trained Support Vector Classifier (SVC) \n",
    "to predict whether a new passenger (user input) survived or not.\n",
    "\n",
    "Steps:\n",
    "1. Provide the encoded user input to the trained model.\n",
    "2. The model predicts survival (1) or not survival (0).\n",
    "3. Translate the numeric prediction into a readable label (\"SURVIVED\" / \"NOT SURVIVED\").\n",
    "4. Display the prediction in a nicely formatted PrettyTable.\n",
    "\"\"\"\n",
    "\n",
    "# Use the trained model to predict survival based on user input\n",
    "predicted_survival = model.predict(unseen_data_features)\n",
    "\n",
    "# Convert numeric prediction (0/1) into a meaningful label\n",
    "if predicted_survival == 1: \n",
    "    prediction = \"SURVIVED\"\n",
    "if predicted_survival == 0:\n",
    "    prediction = \"NOT SURVIVED\"\n",
    "\n",
    "# Create a PrettyTable to display the prediction nicely\n",
    "pretty_table = PrettyTable()\n",
    "pretty_table.add_column(\"       ** Prediction **       \", [prediction])\n",
    "\n",
    "# Print the result\n",
    "print(pretty_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faad2ec8-433c-4fd3-aae8-7784e953f15c",
   "metadata": {},
   "source": [
    "### Step 9: Execute the Feedback Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a688271-6441-4ef6-adde-04f5f5a37d15",
   "metadata": {},
   "source": [
    "#### Step 9.1: Collect Feedback from Users and Domain Experts on Performance of the Model Deployed in the Real World"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e76210-de7c-444a-a9b7-ec937d7c9cc1",
   "metadata": {},
   "source": [
    "#### Step 9.2: Make a List of Potential Improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d36c44-affc-43c7-9c78-aa153ed60f28",
   "metadata": {},
   "source": [
    "#### Step 9.3: Improve the Model Based on Feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db746b3f-726c-41cf-a0e4-7d44d8b51859",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "The analysis shows that survival on the Titanic was strongly influenced by gender, class, and age. Women, children, and first-class passengers had the highest survival rates. The predictive models confirmed these patterns, with [your best model] performing best overall. Despite dataset limitations, the study highlights how socio-economic and demographic factors shaped survival outcomes in the disaster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d15e25-ca9a-4694-9000-af22a6a4153f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
